lines(york.output$original.x.values, york.output$fitted.y , col = "red",lwd = 2)
lines(york.output$original.x.values, york.output$fitted.y.ols, col = "blue", lty = "dashed",lwd = 2)
legend("topright",legend = c("OLS","York","Orthogonal"), fill = c("blue","red","green"))
#the York regression line and the OLS regression line both go to the "center of gravity"
abline(v = york.output$mean.x, h = york.output$mean.y, lty = "dashed", col = "red")
points(x = york.output$mean.x, y = york.output$mean.y, col = "red", pch = 16)
abline(v = mean(york.output$original.x.values), h = mean(york.output$original.y.values) ,lty = "dashed", col = "blue")
points(x = mean(york.output$original.x.values), y = mean(york.output$original.y.values), col = "blue", pch = 16)
?par
wx = par("usr")[1:2]
new.x = seq(wx[1],wx[2],len=100)
pred = predict(lm.OLS, new=data.frame(x=new.x), interval="conf")
#lines(new.x,pred[,"fit"],lwd=2, col = "blue")
lines(new.x,pred[,"lwr"],lty=3,col="blue")
lines(new.x,pred[,"upr"],lty=3,col="blue")
compare.OLS.York <- recordPlot()
plot(york.output$original.x.values, york.output$original.y.values,
xlab = "x data",
ylab = "y data",
main = "Pearson's data with York's weights: Best fit straight line",
col = "black",
pch = 16,
las = 1,
ylim = c(1.5,6))
lines(york.output$original.x.values,york.output$fitted.y.orthogonal, col = "green",lwd = 2)
lines(york.output$original.x.values, york.output$fitted.y , col = "red",lwd = 2)
lines(york.output$original.x.values, york.output$fitted.y.ols, col = "blue", lty = "dashed",lwd = 2)
legend("topright",legend = c("OLS","York","Orthogonal"), fill = c("blue","red","green"))
#the York regression line and the OLS regression line both go to the "center of gravity"
abline(v = york.output$mean.x, h = york.output$mean.y, lty = "dashed", col = "red")
points(x = york.output$mean.x, y = york.output$mean.y, col = "red", pch = 16)
abline(v = mean(york.output$original.x.values), h = mean(york.output$original.y.values) ,lty = "dashed", col = "blue")
points(x = mean(york.output$original.x.values), y = mean(york.output$original.y.values), col = "blue", pch = 16)
?par
wx = par("usr")[1:2]
new.x = seq(wx[1],wx[2],len=100)
pred = predict(lm.OLS, new=data.frame(x=new.x), interval="conf")
#lines(new.x,pred[,"fit"],lwd=2, col = "blue")
lines(new.x,pred[,"lwr"],lty=3,col="blue")
lines(new.x,pred[,"upr"],lty=3,col="blue")
gplot2
library(ggplot2)
ddf <- data.frame(x = x , y = y)
pplot <- ggplot(data=ddf, aes(x=york.output$original.x.values, y=york.output$original.y.values))+ geom_abline(aes(slope = york.output$coefficients[2], intercept = york.output$coefficients[1],colour="York")) + geom_abline(aes(slope = lm.OLS$coefficients[2], intercept = lm.OLS$coefficients[1],colour="OLS")) + geom_abline(aes(slope = b.mayor, intercept = a.mayor,colour="Orthogonal")) + labs(colour="") + scale_colour_manual(values=c("blue","green","red"))  + geom_point()
pplot +labs(title="Pearson's data with York's weights: Best fit straight line",
x ="x data", y = "y data") + geom_vline(xintercept = york.output$mean.x, linetype="dashed",
color = "red", size=0.4) + geom_hline(yintercept = york.output$mean.y, linetype="dashed",
color = "red", size=0.4) + geom_vline(xintercept = mean(york.output$original.x.values), linetype="dashed",
color = "blue", size=0.4) + geom_hline(yintercept = mean(york.output$original.y.values), linetype="dashed",
pplot <- ggplot(data=ddf, aes(x=york.output$original.x.values, y=york.output$original.y.values))+ geom_abline(aes(slope = york.output$coefficients[2], intercept = york.output$coefficients[1],colour="York")) + geom_abline(aes(slope = lm.OLS$coefficients[2], intercept = lm.OLS$coefficients[1],colour="OLS")) + geom_abline(aes(slope = b.mayor, intercept = a.mayor,colour="Orthogonal")) + labs(colour="") + scale_colour_manual(values=c("blue","green","red"))  + geom_point()
pplot +labs(title="Pearson's data with York's weights: Best fit straight line",
x ="x data", y = "y data") + geom_vline(xintercept = york.output$mean.x, linetype="dashed",
color = "red", size=0.4) + geom_hline(yintercept = york.output$mean.y, linetype="dashed",
color = "red", size=0.4) + geom_vline(xintercept = mean(york.output$original.x.values), linetype="dashed",
color = "blue", size=0.4) + geom_hline(yintercept = mean(york.output$original.y.values), linetype="dashed",
library(ggplot2)
ddf <- data.frame(x = x , y = y)
pplot <- ggplot(data=ddf, aes(x=york.output$original.x.values, y=york.output$original.y.values))+ geom_abline(aes(slope = york.output$coefficients[2], intercept = york.output$coefficients[1],colour="York")) + geom_abline(aes(slope = lm.OLS$coefficients[2], intercept = lm.OLS$coefficients[1],colour="OLS")) + geom_abline(aes(slope = b.mayor, intercept = a.mayor,colour="Orthogonal")) + labs(colour="") + scale_colour_manual(values=c("blue","green","red"))  + geom_point()
pplot +labs(title="Pearson's data with York's weights: Best fit straight line",
x ="x data", y = "y data") + geom_vline(xintercept = york.output$mean.x, linetype="dashed",
color = "red", size=0.4) + geom_hline(yintercept = york.output$mean.y, linetype="dashed",
color = "red", size=0.4) + geom_vline(xintercept = mean(york.output$original.x.values), linetype="dashed",
color = "blue", size=0.4) + geom_hline(yintercept = mean(york.output$original.y.values), linetype="dashed",
color = "blue", size=0.4)
york <- function(x, y, tolerance = 1e-10, weights.x, weights.y){
#initial value of b is OLS
lm.OLS <- lm(y~x)
slope <- as.numeric(lm.OLS[[1]][2])
se.of.reg.ols <- sqrt( (1 / (length(x) - 2)) * sum((lm.OLS$residuals)^2) )
slope.diff <- 10
count <- 0
slope.per.iteration <- NULL
while (slope.diff > tolerance) {
slope.old <- slope
# omega, Jonas hat aber gesagt: "Lass es weg"
alpha <- sqrt(weights.x * weights.y)
Weight <- alpha^2 / (slope^2 * weights.y + weights.x - 2 * slope * 0 * alpha)
Weight.sum <- sum(Weight)
x.bar <- sum(Weight * x, na.rm = T) / Weight.sum
y.bar <- sum(Weight * y, na.rm = T) / Weight.sum
x.centered <- x - x.bar
y.centered <- y - y.bar
beta <- Weight * ((x.centered / weights.y) + (slope * y.centered / weights.x) - (slope * x.centered + y.centered) * 0 / alpha)
Q1 <- sum(Weight * beta * y.centered, na.rm = T)
Q2 <- sum(Weight * beta * x.centered, na.rm = T)
slope <- Q1 / Q2
slope.diff <- abs(slope - slope.old)
count <- count + 1
slope.per.iteration <- append(slope.per.iteration, slope)
if (count > tolerance^-1)  stop("\nThe slope coefficient does not converge after ",
count,
" iterations. \nHint: You may reduce the tolerance level.",
cat("Slope coefficient for last 5 iterations:"),
for (i in 4:0){
cat("\n\t", count - i, "\t", slope.per.iteration[count - i])
},
cat("\n")
)
}
slope.per.iteration <- data.frame("slope.per.iteration" = slope.per.iteration)
intercept <- y.bar - slope * x.bar
x.adj <- x.bar + beta
x.mean <- sum(Weight * beta, na.rm = T) / (Weight.sum * (length(x) - 2))
u <- x.adj - x.mean
sigma.slope <- sqrt(1 / sum(Weight * u^2, na.rm = T))
sigma.intercept <- sqrt(x.mean^2 * sigma.slope^2 + 1 / Weight.sum)
sigma.slope.intercept <- -x.mean*sigma.slope^2
reduced.chisq <- sum(Weight * (y - slope * x - intercept)^2, na.rm = T) / (length(x) - 2)
sigma.chisq <- sqrt(2 / (length(x) - 2))
fitted.y <- intercept + slope * x
residuals <- y - fitted.y
df.regression <- 2*(length(x)-1)
c <- 0*alpha
x.residuals <- (Weight * (intercept + slope * x - y) * (c - slope * weights.y)) / (weights.y * weights.x)
y.residuals <- (Weight * (intercept + slope * x - y) * (weights.x - slope * c))/ (weights.y * weights.x)
#total least squares/ simple major axis regression
mean.x <- mean(x)
mean.y <- mean(y)
centered.x <- x - mean.x
centered.x
centered.y <- y - mean.y
centered.y
SS.x <-sum(centered.x^2)
SS.x
SS.y <-sum(centered.y^2)
SS.y
SS.xy <-sum((centered.x) * (centered.y))
SS.xy
b.mayor <- (SS.y - SS.x + sqrt((SS.y - SS.x)^2 + 4*(SS.xy)^2)) / (2*SS.xy)
b.mayor
a.mayor <- mean.y - b.mayor * mean.x
a.mayor
fitted.y.orthogonal <- a.mayor + b.mayor * x
fitted.y.orthogonal
r <- SS.xy / (sqrt(SS.x) * sqrt(SS.y))
r
se.b.mayor <- (b.mayor/r) * sqrt((1 - r^2) / (length(x)))
se.a.mayor <- ((1 / length(x)) * (sqrt(var(y)) - sqrt(var(x)) * b.mayor)^2 + (1 - r) * b.mayor * (2 * sqrt(var(x)) * sqrt(var(y)) + ((mean.x  *b.mayor*(1+r)) / (r^2))) )
se.a.mayor
##
mt <- matrix(c(intercept, slope, sigma.intercept, sigma.slope), nrow = 2)
rownames(mt) <- c("intercept", "slope")
colnames(mt) <- c("Estimate", "Std.Error")
est <- list("coefficients" = mt,
"weighting.vector" = Weight,
"x.residuals" = x.residuals,
"y.residuals"= y.residuals,
"fitted.y"=fitted.y,
"df.regression" = df.regression,
"mean.x" = x.bar,
"mean.y" = y.bar ,
"reduced.chisq" = reduced.chisq,
"Std.Error.chisq" = sigma.chisq,
"number.of.iterations" = count,
"slope.after.each.iteration" = slope.per.iteration,
x.centered, y.centered, x, y, x.mean, "show" = x.adj,
"original.x.values" = x,
"original.y.values" = y,
"fitted.y.ols" = lm.OLS$fitted.values,
"se.of.reg.ols" = se.of.reg.ols,
"fitted.y.orthogonal" = fitted.y.orthogonal,
"se.b.mayor" = se.b.mayor,
"se.a.mayor" = se.a.mayor)
return(est)
}
york <- function(x, y, tolerance = 1e-10, weights.x, weights.y){
#initial value of b is OLS
lm.OLS <- lm(y~x)
slope <- as.numeric(lm.OLS[[1]][2])
se.of.reg.ols <- sqrt( (1 / (length(x) - 2)) * sum((lm.OLS$residuals)^2) )
slope.diff <- 10
count <- 0
slope.per.iteration <- NULL
while (slope.diff > tolerance) {
slope.old <- slope
# omega, Jonas hat aber gesagt: "Lass es weg"
alpha <- sqrt(weights.x * weights.y)
Weight <- alpha^2 / (slope^2 * weights.y + weights.x - 2 * slope * 0 * alpha)
Weight.sum <- sum(Weight)
x.bar <- sum(Weight * x, na.rm = T) / Weight.sum
y.bar <- sum(Weight * y, na.rm = T) / Weight.sum
x.centered <- x - x.bar
y.centered <- y - y.bar
beta <- Weight * ((x.centered / weights.y) + (slope * y.centered / weights.x) - (slope * x.centered + y.centered) * 0 / alpha)
Q1 <- sum(Weight * beta * y.centered, na.rm = T)
Q2 <- sum(Weight * beta * x.centered, na.rm = T)
slope <- Q1 / Q2
slope.diff <- abs(slope - slope.old)
count <- count + 1
slope.per.iteration <- append(slope.per.iteration, slope)
if (count > tolerance^-1)  stop("\nThe slope coefficient does not converge after ",
count,
" iterations. \nHint: You may reduce the tolerance level.",
cat("Slope coefficient for last 5 iterations:"),
for (i in 4:0){
cat("\n\t", count - i, "\t", slope.per.iteration[count - i])
},
cat("\n")
)
}
slope.per.iteration <- data.frame("slope.per.iteration" = slope.per.iteration)
intercept <- y.bar - slope * x.bar
x.adj <- x.bar + beta
x.mean <- sum(Weight * beta, na.rm = T) / (Weight.sum * (length(x) - 2))
u <- x.adj - x.mean
sigma.slope <- sqrt(1 / sum(Weight * u^2, na.rm = T))
sigma.intercept <- sqrt(x.mean^2 * sigma.slope^2 + 1 / Weight.sum)
sigma.slope.intercept <- -x.mean*sigma.slope^2
reduced.chisq <- sum(Weight * (y - slope * x - intercept)^2, na.rm = T) / (length(x) - 2)
sigma.chisq <- sqrt(2 / (length(x) - 2))
fitted.y <- intercept + slope * x
residuals <- y - fitted.y
df.regression <- 2*(length(x)-1)
c <- 0*alpha
x.residuals <- (Weight * (intercept + slope * x - y) * (c - slope * weights.y)) / (weights.y * weights.x)
y.residuals <- (Weight * (intercept + slope * x - y) * (weights.x - slope * c))/ (weights.y * weights.x)
#total least squares/ simple major axis regression
mean.x <- mean(x)
mean.y <- mean(y)
centered.x <- x - mean.x
centered.x
centered.y <- y - mean.y
centered.y
SS.x <-sum(centered.x^2)
SS.x
SS.y <-sum(centered.y^2)
SS.y
SS.xy <-sum((centered.x) * (centered.y))
SS.xy
b.mayor <- (SS.y - SS.x + sqrt((SS.y - SS.x)^2 + 4*(SS.xy)^2)) / (2*SS.xy)
b.mayor
a.mayor <- mean.y - b.mayor * mean.x
a.mayor
fitted.y.orthogonal <- a.mayor + b.mayor * x
fitted.y.orthogonal
r <- SS.xy / (sqrt(SS.x) * sqrt(SS.y))
r
se.b.mayor <- (b.mayor/r) * sqrt((1 - r^2) / (length(x)))
se.a.mayor <- ((1 / length(x)) * (sqrt(var(y)) - sqrt(var(x)) * b.mayor)^2 + (1 - r) * b.mayor * (2 * sqrt(var(x)) * sqrt(var(y)) + ((mean.x  *b.mayor*(1+r)) / (r^2))) )
se.a.mayor
##
mt <- matrix(c(intercept, slope, sigma.intercept, sigma.slope), nrow = 2)
rownames(mt) <- c("intercept", "slope")
colnames(mt) <- c("Estimate", "Std.Error")
est <- list("coefficients" = mt,
"weighting.vector" = Weight,
"x.residuals" = x.residuals,
"y.residuals"= y.residuals,
"fitted.y"=fitted.y,
"df.regression" = df.regression,
"mean.x" = x.bar,
"mean.y" = y.bar ,
"reduced.chisq" = reduced.chisq,
"Std.Error.chisq" = sigma.chisq,
"number.of.iterations" = count,
"slope.after.each.iteration" = slope.per.iteration,
x.centered, y.centered, x, y, x.mean, "show" = x.adj,
"original.x.values" = x,
"original.y.values" = y,
"fitted.y.ols" = lm.OLS$fitted.values,
"se.of.reg.ols" = se.of.reg.ols,
"fitted.y.orthogonal" = fitted.y.orthogonal,
"se.b.mayor" = se.b.mayor,
"se.a.mayor" = se.a.mayor)
return(est)
}
plot(york.output$original.x.values, york.output$original.y.values,
xlab = "x data",
ylab = "y data",
main = "Pearson's data with York's weights: Best fit straight line",
col = "black",
pch = 16,
las = 1,
ylim = c(1.5,6))
lines(york.output$original.x.values,york.output$fitted.y.orthogonal, col = "green",lwd = 2)
lines(york.output$original.x.values, york.output$fitted.y , col = "red",lwd = 2)
lines(york.output$original.x.values, york.output$fitted.y.ols, col = "blue", lty = "dashed",lwd = 2)
legend("topright",legend = c("OLS","York","Orthogonal"), fill = c("blue","red","green"))
#the York regression line and the OLS regression line both go to the "center of gravity"
abline(v = york.output$mean.x, h = york.output$mean.y, lty = "dashed", col = "red")
points(x = york.output$mean.x, y = york.output$mean.y, col = "red", pch = 16)
abline(v = mean(york.output$original.x.values), h = mean(york.output$original.y.values) ,lty = "dashed", col = "blue")
points(x = mean(york.output$original.x.values), y = mean(york.output$original.y.values), col = "blue", pch = 16)
?par
wx = par("usr")[1:2]
new.x = seq(wx[1],wx[2],len=100)
pred = predict(lm.OLS, new=data.frame(x=new.x), interval="conf")
#lines(new.x,pred[,"fit"],lwd=2, col = "blue")
lines(new.x,pred[,"lwr"],lty=3,col="blue")
lines(new.x,pred[,"upr"],lty=3,col="blue")
york <- function(x, y, tolerance = 1e-10, weights.x, weights.y){
#initial value of b is OLS
lm.OLS <- lm(y~x)
slope <- as.numeric(lm.OLS[[1]][2])
se.of.reg.ols <- sqrt( (1 / (length(x) - 2)) * sum((lm.OLS$residuals)^2) )
slope.diff <- 10
count <- 0
slope.per.iteration <- NULL
while (slope.diff > tolerance) {
slope.old <- slope
# omega, Jonas hat aber gesagt: "Lass es weg"
alpha <- sqrt(weights.x * weights.y)
Weight <- alpha^2 / (slope^2 * weights.y + weights.x - 2 * slope * 0 * alpha)
Weight.sum <- sum(Weight)
x.bar <- sum(Weight * x, na.rm = T) / Weight.sum
y.bar <- sum(Weight * y, na.rm = T) / Weight.sum
x.centered <- x - x.bar
y.centered <- y - y.bar
beta <- Weight * ((x.centered / weights.y) + (slope * y.centered / weights.x) - (slope * x.centered + y.centered) * 0 / alpha)
Q1 <- sum(Weight * beta * y.centered, na.rm = T)
Q2 <- sum(Weight * beta * x.centered, na.rm = T)
slope <- Q1 / Q2
slope.diff <- abs(slope - slope.old)
count <- count + 1
slope.per.iteration <- append(slope.per.iteration, slope)
if (count > tolerance^-1)  stop("\nThe slope coefficient does not converge after ",
count,
" iterations. \nHint: You may reduce the tolerance level.",
cat("Slope coefficient for last 5 iterations:"),
for (i in 4:0){
cat("\n\t", count - i, "\t", slope.per.iteration[count - i])
},
cat("\n")
)
}
slope.per.iteration <- data.frame("slope.per.iteration" = slope.per.iteration)
intercept <- y.bar - slope * x.bar
x.adj <- x.bar + beta
x.mean <- sum(Weight * beta, na.rm = T) / (Weight.sum * (length(x) - 2))
u <- x.adj - x.mean
sigma.slope <- sqrt(1 / sum(Weight * u^2, na.rm = T))
sigma.intercept <- sqrt(x.mean^2 * sigma.slope^2 + 1 / Weight.sum)
sigma.slope.intercept <- -x.mean*sigma.slope^2
reduced.chisq <- sum(Weight * (y - slope * x - intercept)^2, na.rm = T) / (length(x) - 2)
sigma.chisq <- sqrt(2 / (length(x) - 2))
fitted.y <- intercept + slope * x
residuals <- y - fitted.y
df.regression <- 2*(length(x)-1)
c <- 0*alpha
x.residuals <- (Weight * (intercept + slope * x - y) * (c - slope * weights.y)) / (weights.y * weights.x)
y.residuals <- (Weight * (intercept + slope * x - y) * (weights.x - slope * c))/ (weights.y * weights.x)
#total least squares/ simple major axis regression
mean.x <- mean(x)
mean.y <- mean(y)
centered.x <- x - mean.x
centered.x
centered.y <- y - mean.y
centered.y
SS.x <-sum(centered.x^2)
SS.x
SS.y <-sum(centered.y^2)
SS.y
SS.xy <-sum((centered.x) * (centered.y))
SS.xy
b.mayor <- (SS.y - SS.x + sqrt((SS.y - SS.x)^2 + 4*(SS.xy)^2)) / (2*SS.xy)
b.mayor
a.mayor <- mean.y - b.mayor * mean.x
a.mayor
fitted.y.orthogonal <- a.mayor + b.mayor * x
fitted.y.orthogonal
r <- SS.xy / (sqrt(SS.x) * sqrt(SS.y))
r
se.b.mayor <- (b.mayor/r) * sqrt((1 - r^2) / (length(x)))
se.a.mayor <- ((1 / length(x)) * (sqrt(var(y)) - sqrt(var(x)) * b.mayor)^2 + (1 - r) * b.mayor * (2 * sqrt(var(x)) * sqrt(var(y)) + ((mean.x  *b.mayor*(1+r)) / (r^2))) )
se.a.mayor
##
mt <- matrix(c(intercept, slope, sigma.intercept, sigma.slope), nrow = 2)
rownames(mt) <- c("intercept", "slope")
colnames(mt) <- c("Estimate", "Std.Error")
est <- list("coefficients" = mt,
"weighting.vector" = Weight,
"x.residuals" = x.residuals,
"y.residuals"= y.residuals,
"fitted.y"=fitted.y,
"df.regression" = df.regression,
"mean.x" = x.bar,
"mean.y" = y.bar ,
"reduced.chisq" = reduced.chisq,
"Std.Error.chisq" = sigma.chisq,
"number.of.iterations" = count,
"slope.after.each.iteration" = slope.per.iteration,
x.centered, y.centered, x, y, x.mean, "show" = x.adj,
"original.x.values" = x,
"original.y.values" = y,
"fitted.y.ols" = lm.OLS$fitted.values,
"se.of.reg.ols" = se.of.reg.ols,
"fitted.y.orthogonal" = fitted.y.orthogonal,
"se.b.mayor" = se.b.mayor,
"se.a.mayor" = se.a.mayor)
return(est)
}
york <- function(x, y, tolerance = 1e-10, weights.x, weights.y){
#initial value of b is OLS
lm.OLS <- lm(y~x)
slope <- as.numeric(lm.OLS[[1]][2])
se.of.reg.ols <- sqrt( (1 / (length(x) - 2)) * sum((lm.OLS$residuals)^2) )
slope.diff <- 10
count <- 0
slope.per.iteration <- NULL
while (slope.diff > tolerance) {
slope.old <- slope
# omega, Jonas hat aber gesagt: "Lass es weg"
alpha <- sqrt(weights.x * weights.y)
Weight <- alpha^2 / (slope^2 * weights.y + weights.x - 2 * slope * 0 * alpha)
Weight.sum <- sum(Weight)
x.bar <- sum(Weight * x, na.rm = T) / Weight.sum
y.bar <- sum(Weight * y, na.rm = T) / Weight.sum
x.centered <- x - x.bar
y.centered <- y - y.bar
beta <- Weight * ((x.centered / weights.y) + (slope * y.centered / weights.x) - (slope * x.centered + y.centered) * 0 / alpha)
Q1 <- sum(Weight * beta * y.centered, na.rm = T)
Q2 <- sum(Weight * beta * x.centered, na.rm = T)
slope <- Q1 / Q2
slope.diff <- abs(slope - slope.old)
count <- count + 1
slope.per.iteration <- append(slope.per.iteration, slope)
if (count > tolerance^-1)  stop("\nThe slope coefficient does not converge after ",
count,
" iterations. \nHint: You may reduce the tolerance level.",
cat("Slope coefficient for last 5 iterations:"),
for (i in 4:0){
cat("\n\t", count - i, "\t", slope.per.iteration[count - i])
},
cat("\n")
)
}
slope.per.iteration <- data.frame("slope.per.iteration" = slope.per.iteration)
intercept <- y.bar - slope * x.bar
x.adj <- x.bar + beta
x.mean <- sum(Weight * beta, na.rm = T) / (Weight.sum * (length(x) - 2))
u <- x.adj - x.mean
sigma.slope <- sqrt(1 / sum(Weight * u^2, na.rm = T))
sigma.intercept <- sqrt(x.mean^2 * sigma.slope^2 + 1 / Weight.sum)
sigma.slope.intercept <- -x.mean*sigma.slope^2
reduced.chisq <- sum(Weight * (y - slope * x - intercept)^2, na.rm = T) / (length(x) - 2)
sigma.chisq <- sqrt(2 / (length(x) - 2))
fitted.y <- intercept + slope * x
residuals <- y - fitted.y
df.regression <- 2*(length(x)-1)
c <- 0*alpha
x.residuals <- (Weight * (intercept + slope * x - y) * (c - slope * weights.y)) / (weights.y * weights.x)
y.residuals <- (Weight * (intercept + slope * x - y) * (weights.x - slope * c))/ (weights.y * weights.x)
#total least squares/ simple major axis regression
mean.x <- mean(x)
mean.y <- mean(y)
centered.x <- x - mean.x
centered.x
centered.y <- y - mean.y
centered.y
SS.x <-sum(centered.x^2)
SS.x
SS.y <-sum(centered.y^2)
SS.y
SS.xy <-sum((centered.x) * (centered.y))
SS.xy
b.mayor <- (SS.y - SS.x + sqrt((SS.y - SS.x)^2 + 4*(SS.xy)^2)) / (2*SS.xy)
b.mayor
a.mayor <- mean.y - b.mayor * mean.x
a.mayor
fitted.y.orthogonal <- a.mayor + b.mayor * x
fitted.y.orthogonal
r <- SS.xy / (sqrt(SS.x) * sqrt(SS.y))
r
se.b.mayor <- (b.mayor/r) * sqrt((1 - r^2) / (length(x)))
se.a.mayor <- ((1 / length(x)) * (sqrt(var(y)) - sqrt(var(x)) * b.mayor)^2 + (1 - r) * b.mayor * (2 * sqrt(var(x)) * sqrt(var(y)) + ((mean.x  *b.mayor*(1+r)) / (r^2))) )
se.a.mayor
##
mt <- matrix(c(intercept, slope, sigma.intercept, sigma.slope), nrow = 2)
rownames(mt) <- c("intercept", "slope")
colnames(mt) <- c("Estimate", "Std.Error")
est <- list("coefficients" = mt,
"weighting.vector" = Weight,
"x.residuals" = x.residuals,
"y.residuals"= y.residuals,
"fitted.y"=fitted.y,
"df.regression" = df.regression,
"mean.x" = x.bar,
"mean.y" = y.bar ,
"reduced.chisq" = reduced.chisq,
"Std.Error.chisq" = sigma.chisq,
"number.of.iterations" = count,
"slope.after.each.iteration" = slope.per.iteration,
x.centered, y.centered, x, y, x.mean, "show" = x.adj,
"original.x.values" = x,
"original.y.values" = y,
"fitted.y.ols" = lm.OLS$fitted.values,
"se.of.reg.ols" = se.of.reg.ols,
"fitted.y.orthogonal" = fitted.y.orthogonal,
"se.b.mayor" = se.b.mayor,
"se.a.mayor" = se.a.mayor)
return(est)
}
york.output <- york(x, y, weights.x = weights.x, weights.y = weights.y)
york.output
york.output$coefficients
plot(york.output$x.residuals, york.output$y.residuals,
xlab = "x residuals",
ylab = "y residuals",
main = "x residuals vs. y residuals",
col = "black",
pch = 16,
las = 1)
abline(h = 0, lty = "dashed", col = "red")
plot(york.output$fitted.y, york.output$x.residuals,
xlab = "fitted y",
ylab = "x residuals",
main = "x residuals vs. fitted plot",
col = "black",
pch = 16,
las = 1)
abline(h = 0, lty = "dashed", col = "red")
plot(lm.OLS)
